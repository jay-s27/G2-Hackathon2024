{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import files\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the website \n",
    "r=requests.get('https://www.producthunt.com/coming-soon?ref=header_nav')\n",
    "\n",
    "#File to store the retrieved product names\n",
    "file=open('new_products.csv','w')\n",
    "csv_writer = csv.writer(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#debug- check response of website\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parse the site\n",
    "soup = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "#retrieve the main div which has id=\"__next\"\n",
    "element=soup.find('div',id=\"__next\")\n",
    "\n",
    "#find all the div elements inside \"__next\"\n",
    "ele2=element.find_all('div') #returned as list\n",
    "ele3=None\n",
    "for element in ele2:\n",
    "    if(element.find('main')): #find the 'main' tag\n",
    "        ele3=element\n",
    "\n",
    "ele4=ele3.find('main',class_=\"styles_itemsContainer__tIyVQ styles_main__osJg3\")\n",
    "ele5=ele4.find('div')\n",
    "ele6=ele5.find('div',class_=\"flex flex-col pb-12\")\n",
    "ele7=ele6.find_all('div')\n",
    "\n",
    "for element in ele7:\n",
    "    if(element.find('div',class_=\"flex flex-row items-start justify-between gap-3 sm:gap-6\")):\n",
    "        ele8=element.find('div',class_=\"flex flex-col justify-center\")\n",
    "\n",
    "        #element that contains the product name\n",
    "        ele9=ele8.find('div',attrs={'data-test': 'product-item-name'})\n",
    "        t=ele9.text #retrieve the text it contains\n",
    "        l=t.split('â€”')  #split the data to only extract product name\n",
    "        data=[l[0]] #add the name as element to list\n",
    "        csv_writer.writerow(data) #add the product name into csv\n",
    "file.close() "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
